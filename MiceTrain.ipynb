{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UoMxG_YI2gz",
        "outputId": "63e4556a-4ecf-4966-9bad-c32c1c3d222b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# run if using google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/FCN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgLADaaxIRS9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import regularizers, initializers, Input, Model\n",
        "from keras.layers import MaxPool2D, Conv2D, Conv2DTranspose, Lambda, Dropout, Add, UpSampling2D, concatenate\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm #to create a task bar\n",
        "from albumentations import CenterCrop, RandomRotate90, GridDistortion, HorizontalFlip, VerticalFlip\n",
        "\n",
        "#import data, models\n",
        "\n",
        "# for auto-reloading external modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHgcVg9y4516"
      },
      "outputs": [],
      "source": [
        "def split_dataset(DATASET_PATH='rats_data', holdout=0.8):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    treatments = os.listdir(DATASET_PATH)\n",
        "    for treatment in treatments:\n",
        "        if treatment == 'CIC' or treatment == 'PDX':\n",
        "            days = os.listdir(os.path.join(DATASET_PATH, treatment))\n",
        "            for day in days:\n",
        "                animals = os.listdir(os.path.join(DATASET_PATH, treatment, day))\n",
        "                for animal in animals:\n",
        "                    path = os.path.join(DATASET_PATH, treatment, day, animal)\n",
        "                    images.append(os.path.join(path, animal+'.png'))\n",
        "                    labels.append(os.path.join(path, animal+'_label.png'))\n",
        "        else:\n",
        "            doses = os.listdir(os.path.join(DATASET_PATH, treatment))\n",
        "            for dose in doses:\n",
        "                days = os.listdir(os.path.join(DATASET_PATH, treatment, dose))\n",
        "                for day in days:\n",
        "                    animals = os.listdir(os.path.join(DATASET_PATH, treatment, dose, day))\n",
        "                    for animal in animals:\n",
        "                        path = os.path.join(DATASET_PATH, treatment, dose, day, animal)\n",
        "                        images.append(os.path.join(path, animal+'.png'))\n",
        "                        labels.append(os.path.join(path, animal+'_label.png'))\n",
        "\n",
        "    return train_test_split(images, labels, test_size=1-holdout, random_state=np.random.randint(0,1000000))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def augment_data(images, masks, save_list_images, save_list_masks):\n",
        "    H = 1024\n",
        "    W = 768\n",
        "\n",
        "    for x, y in tqdm(zip(images, masks), total=len(images)):\n",
        "        name = x.split(\"/\")[-1].split(\".\")\n",
        "        \"\"\" Extracting the name and extension of the image and the mask. \"\"\"\n",
        "        image_name = name[0]\n",
        "        image_extn = name[1]\n",
        "\n",
        "        name = y.split(\"/\")[-1].split(\".\")\n",
        "        mask_name = name[0]\n",
        "        mask_extn = name[1]\n",
        "\n",
        "        \"\"\" Reading image and mask. \"\"\"\n",
        "        x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "        y = cv2.imread(y, cv2.IMREAD_COLOR)\n",
        "\n",
        "        \"\"\" Augmentation \"\"\"\n",
        "        aug = CenterCrop(600, 600, p=1.0)\n",
        "        augmented = aug(image=x, mask=y)\n",
        "        x1 = augmented[\"image\"]\n",
        "        y1 = augmented[\"mask\"]\n",
        "\n",
        "        aug = RandomRotate90(p=1.0)\n",
        "        augmented = aug(image=x, mask=y)\n",
        "        x2 = augmented['image']\n",
        "        y2 = augmented['mask']\n",
        "\n",
        "        aug = GridDistortion(p=1.0)\n",
        "        augmented = aug(image=x, mask=y)\n",
        "        x3 = augmented['image']\n",
        "        y3 = augmented['mask']\n",
        "\n",
        "        aug = HorizontalFlip(p=1.0)\n",
        "        augmented = aug(image=x, mask=y)\n",
        "        x4 = augmented['image']\n",
        "        y4 = augmented['mask']\n",
        "\n",
        "        aug = VerticalFlip(p=1.0)\n",
        "        augmented = aug(image=x, mask=y)\n",
        "        x5 = augmented['image']\n",
        "        y5 = augmented['mask']\n",
        "\n",
        "        save_images = [x1, x2, x3, x4, x5]\n",
        "        save_masks =  [y1, y2, y3, y4, y5]\n",
        "\n",
        "        \"\"\" Saving the image and mask. \"\"\"\n",
        "        idx = 0\n",
        "        for i, m in zip(save_images, save_masks):\n",
        "            i = cv2.resize(i, (W, H))\n",
        "            m = cv2.resize(m, (W, H))\n",
        "\n",
        "            if len(images) == 1:\n",
        "                tmp_img_name = f\"{image_name}.{image_extn}\"\n",
        "                tmp_mask_name = f\"{mask_name}.{mask_extn}\"\n",
        "\n",
        "            else:\n",
        "                tmp_img_name = f\"{image_name}_{idx}.{image_extn}\"\n",
        "                tmp_mask_name = f\"{mask_name}_{idx}.{mask_extn}\"\n",
        "\n",
        "            #image_path = os.path.join(save_path, \"images\", tmp_img_name)\n",
        "            #mask_path = os.path.join(save_path, \"masks\", tmp_mask_name)\n",
        "\n",
        "            #cv2.imwrite(image_path, i)\n",
        "            #cv2.imwrite(mask_path, m)\n",
        "\n",
        "            save_list_images.append(i)\n",
        "            save_list_masks.append(m)\n",
        "\n",
        "\n",
        "            idx += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAiz-3SOdAAQ"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vgg16(weight_decay=0, dropout=0.5):\n",
        "    '''\n",
        "    VGG16 network\n",
        "    \n",
        "    args:\n",
        "        weight_decay = L2 regularization factor (float), weight_decay=0 by default\n",
        "        dropout = dropout rate (float), dropout=0.5 by default\n",
        "        classes = number of classes\n",
        "    return:\n",
        "        Keras model\n",
        "    '''\n",
        "    \n",
        "    ##Input as keras tensor\n",
        "    input = Input(shape=(None, None, 3), name='input')\n",
        "\n",
        "    ##Block 1 - 64 filters\n",
        "    x = Conv2D(filters = 64,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv1-1')(input)\n",
        "\n",
        "    x = Conv2D(filters=64,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv1-2')(x)\n",
        "\n",
        "    x = MaxPool2D(pool_size=(2,2),\n",
        "                    strides=(2,2),\n",
        "                    name='Pool1')(x)\n",
        "\n",
        "    ##Block 2 - 128 filters\n",
        "    x = Conv2D(filters=128,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv2-1')(x)\n",
        "\n",
        "    x = Conv2D(filters=128,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv2-2')(x)\n",
        "    \n",
        "    x = MaxPool2D(pool_size=(2,2),\n",
        "                    strides=(2,2),\n",
        "                    name='Pool2')(x)\n",
        "    \n",
        "    ##Block 3 - 256 filters\n",
        "    x = Conv2D(filters=256,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv3-1')(x)\n",
        "\n",
        "    x = Conv2D(filters=256,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv3-2')(x)\n",
        "\n",
        "    x = Conv2D(filters=256,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv3-3')(x)\n",
        "\n",
        "    x = MaxPool2D(pool_size=(2,2),\n",
        "                    strides=(2,2),\n",
        "                    name='Pool3')(x)\n",
        "\n",
        "    ##Block 4 - 512 filters\n",
        "    x = Conv2D(filters=512,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv4-1')(x)\n",
        "\n",
        "    x = Conv2D(filters=512,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv4-2')(x)\n",
        "\n",
        "    x = Conv2D(filters=512,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv4-3')(x)\n",
        "\n",
        "    x = MaxPool2D(pool_size=(2,2),\n",
        "                    strides=(2,2),\n",
        "                    name='Pool4')(x)\n",
        "\n",
        "    ##Block 5 - 512 filters\n",
        "    x = Conv2D(filters=512,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv5-1')(x)\n",
        "\n",
        "    x = Conv2D(filters=512,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv5-2')(x)\n",
        "\n",
        "    x = Conv2D(filters=512,\n",
        "                kernel_size=(3,3),\n",
        "                padding='same',\n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='Conv5-3')(x)\n",
        "\n",
        "    x = MaxPool2D(pool_size=(2,2),\n",
        "                    strides=(2,2),\n",
        "                    name='Pool5')(x)\n",
        "\n",
        "    ## FC --> Convolutionized Fully Connected Layers\n",
        "\n",
        "    x = Conv2D(filters=4096, \n",
        "                kernel_size=(7,7), \n",
        "                strides=(1,1), \n",
        "                padding='same', \n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay), \n",
        "                name='conv6')(x)\n",
        "\n",
        "    x = Dropout(rate=dropout, name='drop-conv6')(x)\n",
        "\n",
        "    x = Conv2D(filters=4096, \n",
        "                kernel_size=(1,1), \n",
        "                strides=(1,1), \n",
        "                padding='same', \n",
        "                activation='relu',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay), \n",
        "                name='conv7')(x)\n",
        "\n",
        "    x = Dropout(rate=dropout, name='drop-conv7')(x)\n",
        "\n",
        "    return Model(input, x)\n",
        "\n",
        "\n",
        "\n",
        "def fcn32s(vgg16, weight_decay=0):\n",
        "    '''\n",
        "    32x upsampled\n",
        "    \n",
        "    Args:\n",
        "        vgg16: VGG16 model\n",
        "        fcn16: FCN16 model\n",
        "        weight_decay = L2 regularization factor (float), weight_decay=0 by default\n",
        "    returns:\n",
        "        keras model\n",
        "    '''\n",
        "\n",
        "    x = Conv2D(filters=3, \n",
        "                kernel_size=(1,1), \n",
        "                strides=(1,1), \n",
        "                padding='same', \n",
        "                activation='linear',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='score-conv7')(vgg16.get_layer('drop-conv7').output)\n",
        "\n",
        "    x = UpSampling2D(size=(32,32), interpolation='bilinear', name='upsample-32')(x)\n",
        "\n",
        "    x = Conv2D(filters=3, \n",
        "                kernel_size=(1,1),\n",
        "                strides=(1,1),\n",
        "                padding='same',\n",
        "                activation='linear',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='FCN32s')(x)\n",
        "\n",
        "    return Model(vgg16.input, x)\n",
        "\n",
        "\n",
        "\n",
        "def fcn16s(vgg16, fcn32, weight_decay=0):\n",
        "    '''\n",
        "    16x upsampled \n",
        "    \n",
        "    Args:\n",
        "        vgg16: VGG16 custom keras model\n",
        "        fcn32: FCN32 custom keras model\n",
        "        weight_decay = L2 regularization factor (float), weight_decay=0 by default\n",
        "    returns:\n",
        "        keras model\n",
        "    '''\n",
        "    x = UpSampling2D(size=(2,2), interpolation='bilinear')(vgg16.get_layer('drop-conv7').output)\n",
        "\n",
        "    x = Conv2D(filters=21, \n",
        "                kernel_size=(1,1),\n",
        "                strides=(1,1),\n",
        "                padding='same',\n",
        "                activation='linear',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='upsample-conv7')(x)\n",
        "\n",
        "    y = Conv2D(filters=21, \n",
        "                kernel_size=(1,1), \n",
        "                strides=(1,1),\n",
        "                padding='same',  \n",
        "                activation='linear',\n",
        "                kernel_initializer=initializers.Zeros(), #Net starts with unmodified predictions\n",
        "                kernel_regularizer=regularizers.l2(l2=weight_decay) \n",
        "                )(vgg16.get_layer('Pool4').output)\n",
        "\n",
        "    m = Add(name='step4')([x,y]) ##fusion\n",
        "\n",
        "    m  = UpSampling2D(size=(16,16), interpolation='bilinear', name='FCN16s')(m)\n",
        "\n",
        "    x = Conv2D(filters=21, \n",
        "                kernel_size=(1,1),\n",
        "                strides=(1,1),\n",
        "                padding='same',\n",
        "                activation='linear',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='FCN16s')(m)\n",
        "\n",
        "    return Model(fcn32.input, m)\n",
        "\n",
        "    \n",
        "\n",
        "def fcn8s(vgg16, fcn16, weight_decay=0):\n",
        "    '''\n",
        "    8x upsampled\n",
        "    \n",
        "    Args:\n",
        "        vgg16: VGG16 custom keras model\n",
        "        fcn16: FCN16 custom keras model\n",
        "        weight_decay = L2 regularization factor (float), weight_decay=0 by default\n",
        "    returns:\n",
        "        keras model\n",
        "    '''\n",
        "\n",
        "    x = UpSampling2D(size=(2,2), interpolation='bilinear', name='upsampled-step4')(fcn16.get_layer('step4').output)\n",
        "\n",
        "    x = Conv2D(filters=21, \n",
        "                kernel_size=(1,1),\n",
        "                strides=(1,1),\n",
        "                padding='same',\n",
        "                activation='linear',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='upsample-step4')(x)\n",
        "\n",
        "    y = Conv2D(filters=21, \n",
        "                kernel_size=(1,1), \n",
        "                strides=(1,1), \n",
        "                padding='same', \n",
        "                activation='linear', \n",
        "                kernel_regularizer=regularizers.l2(l2=weight_decay), \n",
        "                )(vgg16.get_layer('Pool3').output)\n",
        "\n",
        "    m = Add(name='step3')([x,y])\n",
        "\n",
        "    m = UpSampling2D(size=(8,8), interpolation='bilinear', name='upsampled-step4')(fcn16.get_layer('step4').output)\n",
        "\n",
        "    m = Conv2D(filters=21, \n",
        "                kernel_size=(1,1),\n",
        "                strides=(1,1),\n",
        "                padding='same',\n",
        "                activation='linear',\n",
        "                kernel_regularizer=regularizers.L2(l2=weight_decay),\n",
        "                name='upsample-step4')(m)\n",
        "\n",
        "    return Model(fcn16.input, m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j3ltEpoDvCDm"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'Input' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\bruno\\anaconda3\\envs\\env_mice_scar_segmentation\\mice_scar_segmentation\\MiceTrain.ipynb Célula: 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=0'>1</a>\u001b[0m \u001b[39m## VGG16 base model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=1'>2</a>\u001b[0m vgg_model \u001b[39m=\u001b[39m vgg16(weight_decay\u001b[39m=\u001b[39;49m\u001b[39m1e-6\u001b[39;49m, dropout\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
            "\u001b[1;32mc:\\Users\\bruno\\anaconda3\\envs\\env_mice_scar_segmentation\\mice_scar_segmentation\\MiceTrain.ipynb Célula: 8\u001b[0m in \u001b[0;36mvgg16\u001b[1;34m(weight_decay, dropout)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=1'>2</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=2'>3</a>\u001b[0m \u001b[39mVGG16 network\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=3'>4</a>\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=9'>10</a>\u001b[0m \u001b[39m    Keras model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=10'>11</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=12'>13</a>\u001b[0m \u001b[39m##Input as keras tensor\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=13'>14</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39m3\u001b[39m), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=15'>16</a>\u001b[0m \u001b[39m##Block 1 - 64 filters\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=16'>17</a>\u001b[0m x \u001b[39m=\u001b[39m Conv2D(filters \u001b[39m=\u001b[39m \u001b[39m64\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=17'>18</a>\u001b[0m             kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=18'>19</a>\u001b[0m             padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=19'>20</a>\u001b[0m             activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=20'>21</a>\u001b[0m             kernel_regularizer\u001b[39m=\u001b[39mregularizers\u001b[39m.\u001b[39mL2(l2\u001b[39m=\u001b[39mweight_decay),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bruno/anaconda3/envs/env_mice_scar_segmentation/mice_scar_segmentation/MiceTrain.ipynb#ch0000005?line=21'>22</a>\u001b[0m             name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mConv1-1\u001b[39m\u001b[39m'\u001b[39m)(\u001b[39minput\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
          ]
        }
      ],
      "source": [
        "## VGG16 base model\n",
        "vgg_model = vgg16(weight_decay=1e-6, dropout=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF2oJ7aQtaY_"
      },
      "outputs": [],
      "source": [
        "## FCN32\n",
        "fcn32 = fcn32s(vgg_model, weight_decay=1e-6)\n",
        "\n",
        "## freeze upsample layer\n",
        "fcn32.get_layer('FCN32s').trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoTVM3R0mjtU"
      },
      "outputs": [],
      "source": [
        "## FCN16\n",
        "fcn16 = fcn16s(vgg_model, fcn32, weight_decay=1e-6)\n",
        "\n",
        "## freeze upsample layer\n",
        "fcn16.get_layer('upsample-conv7').trainable=False\n",
        "fcn16.get_layer('FCN16s').trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0vo4Gsvj0X0"
      },
      "outputs": [],
      "source": [
        "## FCN8\n",
        "fcn8 = fcn8s(vgg_model, fcn16, weight_decay=1e-6)\n",
        "\n",
        "## freeze upsample layer\n",
        "fcn8.get_layer('upsample-step4').trainable=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32a1gcKSdDRF"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAX868FY3ODw"
      },
      "outputs": [],
      "source": [
        "# Some important metrics\n",
        "\n",
        "# get it from: https://github.com/kevinddchen/Keras-FCN/blob/main/models.py\n",
        "\n",
        "def crossentropy(y_true, y_pred_onehot):\n",
        "    '''Custom cross-entropy to handle borders (class = -1).'''\n",
        "    n_valid = tf.math.reduce_sum(tf.cast(y_true != 255, tf.float32))\n",
        "    y_true_onehot = tf.cast(np.arange(21) == y_true, tf.float32)\n",
        "    return tf.reduce_sum(-y_true_onehot * tf.math.log(y_pred_onehot + 1e-7)) / n_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rccnptv-tsZ"
      },
      "outputs": [],
      "source": [
        "def pixelacc(y_true, y_pred_onehot):\n",
        "    '''Custom pixel accuracy to handle borders (class = -1).'''\n",
        "    n_valid = tf.math.reduce_sum(tf.cast(y_true != 255, tf.float32))\n",
        "    y_true = tf.cast(y_true, tf.int32)[..., 0]\n",
        "    y_pred = tf.argmax(y_pred_onehot, axis=-1, output_type=tf.int32)\n",
        "    return tf.reduce_sum(tf.cast(y_true == y_pred, tf.float32)) / n_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9dMHSFz-r27"
      },
      "outputs": [],
      "source": [
        "class MyMeanIoU(keras.metrics.MeanIoU):\n",
        "    '''Custom meanIoU to handle borders (class = -1).'''\n",
        "    def update_state(self, y_true, y_pred_onehot, sample_weight=None):\n",
        "        y_pred = tf.argmax(y_pred_onehot, axis=-1)\n",
        "        ## add 1 so boundary class=0\n",
        "        y_true = tf.cast(y_true+1, self._dtype)\n",
        "        y_pred = tf.cast(y_pred+1, self._dtype)\n",
        "        ## Flatten the input if its rank > 1.\n",
        "        if y_pred.shape.ndims > 1:\n",
        "            y_pred = tf.reshape(y_pred, [-1])\n",
        "        if y_true.shape.ndims > 1:\n",
        "            y_true = tf.reshape(y_true, [-1])\n",
        "        ## calculate confusion matrix with one extra class\n",
        "        current_cm = tf.math.confusion_matrix(\n",
        "            y_true,\n",
        "            y_pred,\n",
        "            self.num_classes+1,\n",
        "            weights=sample_weight,\n",
        "            dtype=self._dtype)\n",
        "        return self.total_cm.assign_add(current_cm[1:, 1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sT6GMTk5naAh"
      },
      "outputs": [],
      "source": [
        "## Load model\n",
        "model = fcn32\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YJSjeho541h"
      },
      "outputs": [],
      "source": [
        "## Train and test datasets\n",
        "X_train, X_test, y_train, y_test = split_dataset('/content/drive/MyDrive/rats_data', holdout=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5V6G6ep5-KZ"
      },
      "outputs": [],
      "source": [
        "X_train_images = []\n",
        "for image in X_train:\n",
        "  img = cv2.imread(image)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  X_train_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB-tffcb5-Uh"
      },
      "outputs": [],
      "source": [
        "X_test_images = []\n",
        "for image in X_test:\n",
        "  img = cv2.imread(image)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  X_test_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3G9krX2F5-cQ"
      },
      "outputs": [],
      "source": [
        "y_train_images = []\n",
        "for image in y_train:\n",
        "  img = cv2.imread(image)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  y_train_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgCdDPH85-ip"
      },
      "outputs": [],
      "source": [
        "y_test_images = []\n",
        "for image in y_test:\n",
        "  img = cv2.imread(image)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  y_test_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Original Images: {len(X_train_images)} - Original Masks: {len(y_train_images)}\")\n",
        "augment_data(X_train, y_train, X_train_images, y_train_images)\n",
        "print(f\"\\nAugmented Images: {len(X_train_images)} - Augmented Masks: {len(y_train_images)}\")\n",
        "\n",
        "print(f\"\\n\\nOriginal Images: {len(X_test_images)} - Original Masks: {len(y_test_images)}\")\n",
        "augment_data(X_test, y_test, X_test_images, y_test_images)\n",
        "print(f\"\\nAugmented Images: {len(X_test_images)} - Augmented Masks: {len(y_test_images)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeI7VAmOI04A"
      },
      "outputs": [],
      "source": [
        "#checking the data\n",
        "\n",
        "n = 5\n",
        "plt.figure(figsize=(25, 25))\n",
        "for i in range(n):\n",
        "  plt.subplot(4, 2, 2*i+1)\n",
        "  plt.imshow(X_train_images[i], )\n",
        "  plt.subplot(4, 2, 2*i+2)\n",
        "  plt.imshow(y_train_images[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZpFcp3-m990"
      },
      "outputs": [],
      "source": [
        "X_train_images = tf.convert_to_tensor(X_train_images)\n",
        "y_train_images = tf.convert_to_tensor(y_train_images)\n",
        "X_test_images = tf.convert_to_tensor(X_test_images)\n",
        "y_test_images = tf.convert_to_tensor(y_test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Lbt_JX26iBJ"
      },
      "outputs": [],
      "source": [
        "## compile\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
        "loss = 'binary_crossentropy'\n",
        "metrics = ['accuracy']\n",
        "model.compile(optimizer=opt, loss=loss, metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py_E7-3Ctpzf"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train_images, y_train_images, batch_size=1, epochs=20, verbose=1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "MiceTrain.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "ed3943dba37f3ed717092a780584c496f36863d6c99891baccd6632ecc02cdda"
    },
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
